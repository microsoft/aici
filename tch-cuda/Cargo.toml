[package]
name = "tch-cuda"
version = "0.1.0"
edition = "2021"

description = "Flash attention layer for the tch-rs"
license = "MIT"
readme = "README.md"

[dependencies]
fxhash = "0.2.1"
half = { version = "2.3.1", features = ["num-traits"] }
libc = "0.2.151"
tch = "0.14.0"
torch-sys = "0.14.0"

[build-dependencies]
anyhow = { version = "1", features = ["backtrace"] }
num_cpus = "1.15.0"
rayon = "1.7.0"
glob = "0.3.1"

[dev-dependencies]
anyhow = { version = "1", features = ["backtrace"] }
